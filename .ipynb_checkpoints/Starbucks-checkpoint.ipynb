{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Exercise Starbucks\n",
    "<br>\n",
    "\n",
    "<img src=\"https://opj.ca/wp-content/uploads/2018/02/New-Starbucks-Logo-1200x969.jpg\" width=\"200\" height=\"200\">\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "#### Background Information\n",
    "\n",
    "The dataset you will be provided in this portfolio exercise was originally used as a take-home assignment provided by Starbucks for their candidates.   The data for this exercise consists of about 120,000 data points split in 2:1 ratio among training and test files. Each data point includes one column indicating whether or not an individual was sent a promotion for a specific product, and one column indicating whether or not that individual eventually purchased that product. Each individual also had seven additional features associated with them.\n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "Your task is to use the training data to understand what patterns in V1-V7 to indicate that a promotion should be provided to a user.  Specifically, your goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "Ratio of the number of purchasers in the promotion group to the total number of customers in the purchasers group minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group.\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "The total number of purchasers that received the promotion times 10 minus the number of promotions given times 0.15 minus the number of purchasers who were not given the promotion times 10.\n",
    "\n",
    "For a full description of what starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "Below you can find the training data provided.  Explore the data and different optimization strategies.\n",
    "\n",
    "#### How To Test Your Strategy?\n",
    "\n",
    "When you feel like you have an optimization strategy, complete the **promotion_strategy** function to pass to the **test_results** function.  \n",
    "From past data, we know there are four possible outomes:\n",
    "\n",
    "Table of actual promotion vs. predicted promotion customers.  \n",
    "\n",
    "|   | Actual      |    |    | \n",
    "|---|-------------|----|----|\n",
    "| **Predicted**   | Yes| No |  \n",
    "| Yes             | **I**   | **II**|  \n",
    "| No              | **III** | **IV**|  \n",
    "\n",
    "The metrics are only being compared for the individual's we predict should obtain the promotion - that is quadrants I and II here.  Since the first set of individuals that receive the promotion (in the training set) receive it randomly, we can expect that quadrants I and II will have approximately equal participants.  \n",
    "\n",
    "Comparing quadrant I to II then gives an idea of how well your promotion strategy will work in the future. \n",
    "\n",
    "\n",
    "Get started by reading in the data below.  See how each variable or combination of variables along with a promotion influences the chance of purchasing.  When you feel like you have a strategy for who should receive a promotion, test your strategy against the test dataset used in the final test_results function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044332</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044332 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# load in the data\n",
    "train_data = pd.read_csv('data/training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells for you to work and document as necessary - \n",
    "# definitely feel free to add more cells as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    42364\n",
       "No     42170\n",
       "Name: Promotion, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Promotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment variable is balanced. Does not need any resampling techniques to improve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83494\n",
       "1     1040\n",
       "Name: purchase, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.purchase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Promotion    0\n",
       "purchase     0\n",
       "V1           0\n",
       "V2           0\n",
       "V3           0\n",
       "V4           0\n",
       "V5           0\n",
       "V6           0\n",
       "V7           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values in any of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84534 entries, 0 to 84533\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         84534 non-null  int64  \n",
      " 1   Promotion  84534 non-null  object \n",
      " 2   purchase   84534 non-null  int64  \n",
      " 3   V1         84534 non-null  int64  \n",
      " 4   V2         84534 non-null  float64\n",
      " 5   V3         84534 non-null  float64\n",
      " 6   V4         84534 non-null  int64  \n",
      " 7   V5         84534 non-null  int64  \n",
      " 8   V6         84534 non-null  int64  \n",
      " 9   V7         84534 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31631\n",
       "2    31608\n",
       "3    10670\n",
       "0    10625\n",
       "Name: V1, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.V1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    57450\n",
       "1    27084\n",
       "Name: V4, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.V4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    32743\n",
       "2    31196\n",
       "1    15412\n",
       "4     5183\n",
       "Name: V5, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.V5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    21186\n",
       "4    21176\n",
       "2    21146\n",
       "1    21026\n",
       "Name: V6, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.V6.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    59317\n",
       "1    25217\n",
       "Name: V7, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.V7.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1, V4, V5, V6 and V7 all have limited number of integer values. It is unclear whether these are categories encoded as numbers or whether there is ordinality attached to them. For the purposes of this analysis, they will be treated as categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83494\n",
       "1     1040\n",
       "Name: purchase, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.purchase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['promotion_applied'] = train_data['Promotion'].replace(('Yes', 'No'), (1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044332</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7  \\\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2   \n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2   \n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2   \n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2   \n",
       "4   8       Yes         0   3  28.044332 -0.385883   1   1   2   2   \n",
       "\n",
       "   promotion_applied  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  1  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['ID', 'Promotion', 'purchase'])\n",
    "y = train_data['purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-242-2400a6cb4888>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['V{}_T'.format(i)] = X_train['promotion_applied']*X_train['V{}'.format(i)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    X_train['V{}_T'.format(i)] = X_train['promotion_applied']*X_train['V{}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "      <th>V1_T</th>\n",
       "      <th>V2_T</th>\n",
       "      <th>V3_T</th>\n",
       "      <th>V4_T</th>\n",
       "      <th>V5_T</th>\n",
       "      <th>V6_T</th>\n",
       "      <th>V7_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>1</td>\n",
       "      <td>26.495446</td>\n",
       "      <td>1.518828</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.495446</td>\n",
       "      <td>1.518828</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71112</th>\n",
       "      <td>2</td>\n",
       "      <td>34.084350</td>\n",
       "      <td>-0.818772</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.084350</td>\n",
       "      <td>-0.818772</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77043</th>\n",
       "      <td>3</td>\n",
       "      <td>22.648291</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67036</th>\n",
       "      <td>2</td>\n",
       "      <td>25.466314</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.466314</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53133</th>\n",
       "      <td>2</td>\n",
       "      <td>29.202421</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1         V2        V3  V4  V5  V6  V7  promotion_applied  V1_T  \\\n",
       "38968   1  26.495446  1.518828   2   3   1   2                  1     1   \n",
       "71112   2  34.084350 -0.818772   2   3   3   1                  1     2   \n",
       "77043   3  22.648291 -0.645617   2   1   1   2                  0     0   \n",
       "67036   2  25.466314 -0.472461   2   3   2   1                  1     2   \n",
       "53133   2  29.202421 -0.385883   2   3   4   1                  0     0   \n",
       "\n",
       "            V2_T      V3_T  V4_T  V5_T  V6_T  V7_T  \n",
       "38968  26.495446  1.518828     2     3     1     2  \n",
       "71112  34.084350 -0.818772     2     3     3     1  \n",
       "77043   0.000000 -0.000000     0     0     0     0  \n",
       "67036  25.466314 -0.472461     2     3     2     1  \n",
       "53133   0.000000 -0.000000     0     0     0     0  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012456084318109231"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()/(y_train==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    62620\n",
       "1      780\n",
       "Name: purchase, dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   5.1s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   6.1s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   6.4s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   6.4s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   6.4s\n",
      "[CV] END .................................classifier__C=0.01; total time=   6.3s\n",
      "[CV] END .................................classifier__C=0.01; total time=   6.9s\n",
      "[CV] END .................................classifier__C=0.01; total time=   6.4s\n",
      "[CV] END .................................classifier__C=0.01; total time=   6.6s\n",
      "[CV] END .................................classifier__C=0.01; total time=   6.8s\n",
      "[CV] END ..................................classifier__C=100; total time=   6.7s\n",
      "[CV] END ..................................classifier__C=100; total time=   6.5s\n",
      "[CV] END ..................................classifier__C=100; total time=   6.7s\n",
      "[CV] END ..................................classifier__C=100; total time=   6.4s\n",
      "[CV] END ..................................classifier__C=100; total time=   6.7s\n",
      "[CV] END ................................classifier__C=10000; total time=   6.9s\n",
      "[CV] END ................................classifier__C=10000; total time=   6.8s\n",
      "[CV] END ................................classifier__C=10000; total time=   6.7s\n",
      "[CV] END ................................classifier__C=10000; total time=   6.7s\n",
      "[CV] END ................................classifier__C=10000; total time=   6.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('upsampler',\n",
       "                                        SMOTENC(categorical_features=[0, 3, 4,\n",
       "                                                                      5, 6, 7,\n",
       "                                                                      8, 11, 12,\n",
       "                                                                      13, 14],\n",
       "                                                random_state=21,\n",
       "                                                sampling_strategy=0.1)),\n",
       "                                       ('downsampler',\n",
       "                                        RandomUnderSampler(random_state=21,\n",
       "                                                           sampling_strategy=0.3)),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           max_iter=200))]),\n",
       "             param_grid={'classifier__C': [0.0001, 0.01, 100, 10000]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "    ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "    ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter = 200, class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__C': [0.0001, 0.01, 100, 10000]\n",
    "}\n",
    "\n",
    "cv_0 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.0001}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166766986872385"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test.copy()\n",
    "for i in range(1,8):\n",
    "    X_test_new['V{}_T'.format(i)] = X_test['promotion_applied']*X_test['V{}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = cv_0.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78     20874\n",
      "           1       0.02      0.69      0.04       260\n",
      "\n",
      "    accuracy                           0.64     21134\n",
      "   macro avg       0.51      0.66      0.41     21134\n",
      "weighted avg       0.98      0.64      0.77     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   9.1s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   9.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   9.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   9.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   9.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.0s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.0s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.6s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  12.2s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  16.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  11.6s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  12.0s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   9.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.4s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  11.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  11.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  14.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  14.7s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=   9.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   9.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   9.0s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.0s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=5; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  11.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=  10.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  12.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.0s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=5; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.1s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=  10.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('upsampler',\n",
       "                                        SMOTENC(categorical_features=[0, 3, 4,\n",
       "                                                                      5, 6, 7,\n",
       "                                                                      8, 11, 12,\n",
       "                                                                      13, 14],\n",
       "                                                random_state=21,\n",
       "                                                sampling_strategy=0.1)),\n",
       "                                       ('downsampler',\n",
       "                                        RandomUnderSampler(random_state=21,\n",
       "                                                           sampling_strategy=0.3)),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_byno...\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'classifier__learning_rate': [0.03, 0.3],\n",
       "                         'classifier__max_depth': [4, 6],\n",
       "                         'classifier__n_estimators': [200],\n",
       "                         'classifier__reg_lambda': [1, 10],\n",
       "                         'classifier__scale_pos_weight': [5, 10]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "    ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "    ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(objective='binary:logistic', random_state=21, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__max_depth': [4,6],\n",
    "    'classifier__learning_rate': [0.03, 0.3],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_lambda': [1, 10],\n",
    "    'classifier__scale_pos_weight': [5,10]\n",
    "}\n",
    "\n",
    "cv_1 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.03,\n",
       " 'classifier__max_depth': 6,\n",
       " 'classifier__n_estimators': 200,\n",
       " 'classifier__reg_lambda': 1,\n",
       " 'classifier__scale_pos_weight': 5}"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5798206929874129"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = cv_1.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84     20874\n",
      "           1       0.02      0.50      0.04       260\n",
      "\n",
      "    accuracy                           0.72     21134\n",
      "   macro avg       0.51      0.61      0.44     21134\n",
      "weighted avg       0.98      0.72      0.83     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   6.6s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   7.6s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   8.2s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   8.2s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   9.0s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=  10.2s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=  11.9s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=  11.1s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   9.8s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   9.6s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   8.2s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   8.3s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   8.3s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=  11.1s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=  10.3s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   9.9s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=  10.0s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   9.9s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   8.6s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   8.5s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   8.6s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=  10.5s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=  10.6s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=  10.3s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=  10.5s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=  10.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('upsampler',\n",
       "                                        SMOTENC(categorical_features=[0, 3, 4,\n",
       "                                                                      5, 6, 7,\n",
       "                                                                      8, 11, 12,\n",
       "                                                                      13, 14],\n",
       "                                                random_state=21,\n",
       "                                                sampling_strategy=0.1)),\n",
       "                                       ('downsampler',\n",
       "                                        RandomUnderSampler(random_state=21,\n",
       "                                                           sampling_strategy=0.3)),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(class_weight='balanced_subsample'))]),\n",
       "             param_grid={'classifier__max_depth': [2, 4, 6],\n",
       "                         'classifier__n_estimators': [100, 200]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "    ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "    ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(class_weight = 'balanced_subsample'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__max_depth': [2,4,6],\n",
    "    'classifier__n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "cv_2 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 4, 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = cv_2.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     20874\n",
      "           1       0.02      0.61      0.05       260\n",
      "\n",
      "    accuracy                           0.68     21134\n",
      "   macro avg       0.51      0.65      0.43     21134\n",
      "weighted avg       0.98      0.68      0.80     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   0.0s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   0.0s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   0.0s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   0.0s\n",
      "[CV] END ...............................classifier__C=0.0001; total time=   0.1s\n",
      "[CV] END .................................classifier__C=0.01; total time=   0.1s\n",
      "[CV] END .................................classifier__C=0.01; total time=   0.2s\n",
      "[CV] END .................................classifier__C=0.01; total time=   0.2s\n",
      "[CV] END .................................classifier__C=0.01; total time=   0.2s\n",
      "[CV] END .................................classifier__C=0.01; total time=   0.2s\n",
      "[CV] END ..................................classifier__C=100; total time=   0.2s\n",
      "[CV] END ..................................classifier__C=100; total time=   0.2s\n",
      "[CV] END ..................................classifier__C=100; total time=   0.2s\n",
      "[CV] END ..................................classifier__C=100; total time=   0.3s\n",
      "[CV] END ..................................classifier__C=100; total time=   0.2s\n",
      "[CV] END ................................classifier__C=10000; total time=   0.2s\n",
      "[CV] END ................................classifier__C=10000; total time=   0.2s\n",
      "[CV] END ................................classifier__C=10000; total time=   0.2s\n",
      "[CV] END ................................classifier__C=10000; total time=   0.2s\n",
      "[CV] END ................................classifier__C=10000; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           max_iter=200))]),\n",
       "             param_grid={'classifier__C': [0.0001, 0.01, 100, 10000]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "#     ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "#     ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter = 200, class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__C': [0.0001, 0.01, 100, 10000]\n",
    "}\n",
    "\n",
    "cv_3 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.79     20874\n",
      "           1       0.02      0.67      0.05       260\n",
      "\n",
      "    accuracy                           0.66     21134\n",
      "   macro avg       0.51      0.66      0.42     21134\n",
      "weighted avg       0.98      0.66      0.78     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_3 = cv_3.predict(X_test_new)\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   7.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   7.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   6.2s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.2s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   7.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   6.1s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   6.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   7.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   6.0s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   7.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   6.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   6.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   7.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   6.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   6.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   7.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.03, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   6.2s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   5.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   6.0s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=4, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   5.8s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=10; total time=   8.3s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=1, classifier__scale_pos_weight=100; total time=   8.6s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=10; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.4s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.5s\n",
      "[CV] END classifier__learning_rate=0.3, classifier__max_depth=6, classifier__n_estimators=200, classifier__reg_lambda=10, classifier__scale_pos_weight=100; total time=   8.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      eval_metric='logloss',\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min...\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'classifier__learning_rate': [0.03, 0.3],\n",
       "                         'classifier__max_depth': [4, 6],\n",
       "                         'classifier__n_estimators': [200],\n",
       "                         'classifier__reg_lambda': [1, 10],\n",
       "                         'classifier__scale_pos_weight': [10, 100]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "#     ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "#     ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', XGBClassifier(objective='binary:logistic', random_state=21, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__max_depth': [4,6],\n",
    "    'classifier__learning_rate': [0.03, 0.3],\n",
    "    'classifier__n_estimators': [200],\n",
    "    'classifier__reg_lambda': [1, 10],\n",
    "    'classifier__scale_pos_weight': [10,100]\n",
    "}\n",
    "\n",
    "cv_4 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82     20874\n",
      "           1       0.02      0.61      0.05       260\n",
      "\n",
      "    accuracy                           0.70     21134\n",
      "   macro avg       0.51      0.66      0.43     21134\n",
      "weighted avg       0.98      0.70      0.81     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_4 = cv_4.predict(X_test_new)\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   2.8s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   3.0s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   2.7s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   2.7s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=100; total time=   2.8s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   5.8s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   6.4s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   5.7s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   5.8s\n",
      "[CV] END classifier__max_depth=2, classifier__n_estimators=200; total time=   6.5s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   5.5s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   5.2s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   3.6s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   3.7s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=100; total time=   3.7s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   7.3s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   8.1s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   8.1s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   7.9s\n",
      "[CV] END classifier__max_depth=4, classifier__n_estimators=200; total time=   7.1s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   4.6s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   4.2s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   4.3s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   4.7s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=100; total time=   4.5s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=   8.1s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=   9.2s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=   9.7s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=   8.7s\n",
      "[CV] END classifier__max_depth=6, classifier__n_estimators=200; total time=   8.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(class_weight='balanced_subsample'))]),\n",
       "             param_grid={'classifier__max_depth': [2, 4, 6],\n",
       "                         'classifier__n_estimators': [100, 200]},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = imbpipeline([\n",
    "#     ('upsampler', SMOTENC(categorical_features = [0,3,4,5,6,7,8,11,12,13,14], sampling_strategy = 0.1, random_state=21)),\n",
    "#     ('downsampler', RandomUnderSampler(sampling_strategy = 0.3, random_state = 21)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(class_weight = 'balanced_subsample'))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'classifier__max_depth': [2,4,6],\n",
    "    'classifier__n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "cv_5 = GridSearchCV(pipeline, param_grid=parameters, scoring = 'balanced_accuracy', cv=5, verbose=2 )\n",
    "\n",
    "cv_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85     20874\n",
      "           1       0.03      0.60      0.05       260\n",
      "\n",
      "    accuracy                           0.74     21134\n",
      "   macro avg       0.51      0.67      0.45     21134\n",
      "weighted avg       0.98      0.74      0.84     21134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_5 = cv_5.predict(X_test_new)\n",
    "print(classification_report(y_test, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "      <th>V1_T</th>\n",
       "      <th>V2_T</th>\n",
       "      <th>V3_T</th>\n",
       "      <th>V4_T</th>\n",
       "      <th>V5_T</th>\n",
       "      <th>V6_T</th>\n",
       "      <th>V7_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>3</td>\n",
       "      <td>35.295214</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>2</td>\n",
       "      <td>35.824522</td>\n",
       "      <td>1.085939</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17797</th>\n",
       "      <td>3</td>\n",
       "      <td>22.322402</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69178</th>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36585</th>\n",
       "      <td>2</td>\n",
       "      <td>32.978397</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72707</th>\n",
       "      <td>1</td>\n",
       "      <td>30.369647</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58509</th>\n",
       "      <td>3</td>\n",
       "      <td>29.885528</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1         V2        V3  V4  V5  V6  V7  promotion_applied  V1_T  \\\n",
       "74988   3  25.140341  0.047006   2   1   3   2                  1     3   \n",
       "26819   3  35.295214 -0.472461   2   4   1   2                  0     0   \n",
       "61906   2  35.824522  1.085939   2   3   3   2                  0     0   \n",
       "17797   3  22.322402  0.826206   1   3   1   2                  0     0   \n",
       "44793   0  30.352434  1.605406   2   2   2   2                  1     0   \n",
       "...    ..        ...       ...  ..  ..  ..  ..                ...   ...   \n",
       "73605   0  26.675765 -1.078506   1   1   2   2                  1     0   \n",
       "69178   1  37.199113 -1.597972   1   1   1   2                  1     1   \n",
       "36585   2  32.978397 -0.212728   2   1   3   2                  0     0   \n",
       "72707   1  30.369647  0.133583   1   3   4   1                  0     0   \n",
       "58509   3  29.885528  0.999361   2   2   2   2                  0     0   \n",
       "\n",
       "            V2_T      V3_T  V4_T  V5_T  V6_T  V7_T  \n",
       "74988  25.140341  0.047006     2     1     3     2  \n",
       "26819   0.000000 -0.000000     0     0     0     0  \n",
       "61906   0.000000  0.000000     0     0     0     0  \n",
       "17797   0.000000  0.000000     0     0     0     0  \n",
       "44793  30.352434  1.605406     2     2     2     2  \n",
       "...          ...       ...   ...   ...   ...   ...  \n",
       "73605  26.675765 -1.078506     1     1     2     2  \n",
       "69178  37.199113 -1.597972     1     1     1     2  \n",
       "36585   0.000000 -0.000000     0     0     0     0  \n",
       "72707   0.000000  0.000000     0     0     0     0  \n",
       "58509   0.000000  0.000000     0     0     0     0  \n",
       "\n",
       "[21134 rows x 15 columns]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-647-1698c40b3d89>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['promotion_app'] = X_test_new['promotion_applied']\n"
     ]
    }
   ],
   "source": [
    "X_test['promotion_app'] = X_test_new['promotion_applied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-526-792348319701>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['promotion_applied'] = 0\n"
     ]
    }
   ],
   "source": [
    "X_test['promotion_applied'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-529-d184705b017b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['V{}_T'.format(i)] = X_test['promotion_applied']*X_test['V{}'.format(i)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    X_test['V{}_T'.format(i)] = X_test['promotion_applied']*X_test['V{}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-535-a7ddb24150f4>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['prob_0'] = cv_3.predict_proba(X_test)[:,1]\n"
     ]
    }
   ],
   "source": [
    "X_test['prob_0'] = cv_3.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-537-b26ba021dd39>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['promotion_applied'] = 1\n"
     ]
    }
   ],
   "source": [
    "X_test['promotion_applied'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-538-d184705b017b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['V{}_T'.format(i)] = X_test['promotion_applied']*X_test['V{}'.format(i)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    X_test['V{}_T'.format(i)] = X_test['promotion_applied']*X_test['V{}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "      <th>V1_T</th>\n",
       "      <th>V2_T</th>\n",
       "      <th>V3_T</th>\n",
       "      <th>V4_T</th>\n",
       "      <th>V5_T</th>\n",
       "      <th>V6_T</th>\n",
       "      <th>V7_T</th>\n",
       "      <th>prob_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>3</td>\n",
       "      <td>35.295214</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.295214</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.378601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>2</td>\n",
       "      <td>35.824522</td>\n",
       "      <td>1.085939</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.824522</td>\n",
       "      <td>1.085939</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.442626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17797</th>\n",
       "      <td>3</td>\n",
       "      <td>22.322402</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.322402</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.348436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.356628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69178</th>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.318143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36585</th>\n",
       "      <td>2</td>\n",
       "      <td>32.978397</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32.978397</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.386402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72707</th>\n",
       "      <td>1</td>\n",
       "      <td>30.369647</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.369647</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58509</th>\n",
       "      <td>3</td>\n",
       "      <td>29.885528</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.885528</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.403063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1         V2        V3  V4  V5  V6  V7  promotion_applied  V1_T  \\\n",
       "74988   3  25.140341  0.047006   2   1   3   2                  1     3   \n",
       "26819   3  35.295214 -0.472461   2   4   1   2                  1     3   \n",
       "61906   2  35.824522  1.085939   2   3   3   2                  1     2   \n",
       "17797   3  22.322402  0.826206   1   3   1   2                  1     3   \n",
       "44793   0  30.352434  1.605406   2   2   2   2                  1     0   \n",
       "...    ..        ...       ...  ..  ..  ..  ..                ...   ...   \n",
       "73605   0  26.675765 -1.078506   1   1   2   2                  1     0   \n",
       "69178   1  37.199113 -1.597972   1   1   1   2                  1     1   \n",
       "36585   2  32.978397 -0.212728   2   1   3   2                  1     2   \n",
       "72707   1  30.369647  0.133583   1   3   4   1                  1     1   \n",
       "58509   3  29.885528  0.999361   2   2   2   2                  1     3   \n",
       "\n",
       "            V2_T      V3_T  V4_T  V5_T  V6_T  V7_T    prob_0  \n",
       "74988  25.140341  0.047006     2     1     3     2  0.366651  \n",
       "26819  35.295214 -0.472461     2     4     1     2  0.378601  \n",
       "61906  35.824522  1.085939     2     3     3     2  0.442626  \n",
       "17797  22.322402  0.826206     1     3     1     2  0.348436  \n",
       "44793  30.352434  1.605406     2     2     2     2  0.504949  \n",
       "...          ...       ...   ...   ...   ...   ...       ...  \n",
       "73605  26.675765 -1.078506     1     1     2     2  0.356628  \n",
       "69178  37.199113 -1.597972     1     1     1     2  0.318143  \n",
       "36585  32.978397 -0.212728     2     1     3     2  0.386402  \n",
       "72707  30.369647  0.133583     1     3     4     1  0.343215  \n",
       "58509  29.885528  0.999361     2     2     2     2  0.403063  \n",
       "\n",
       "[21134 rows x 16 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-550-e7873e1a653f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['prob_1'] = cv_3.predict_proba(X_test.drop(columns = ['prob_0']))[:,1]\n"
     ]
    }
   ],
   "source": [
    "X_test['prob_1'] = cv_3.predict_proba(X_test.drop(columns = ['prob_0']))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-552-e0b244daae93>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['incremental_prob'] = X_test['prob_1'] - X_test['prob_0']\n"
     ]
    }
   ],
   "source": [
    "X_test['incremental_prob'] = X_test['prob_1'] - X_test['prob_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "      <th>V1_T</th>\n",
       "      <th>V2_T</th>\n",
       "      <th>V3_T</th>\n",
       "      <th>V4_T</th>\n",
       "      <th>V5_T</th>\n",
       "      <th>V6_T</th>\n",
       "      <th>V7_T</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>incremental_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56603</th>\n",
       "      <td>3</td>\n",
       "      <td>29.585683</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.585683</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307462</td>\n",
       "      <td>0.733192</td>\n",
       "      <td>0.425730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18866</th>\n",
       "      <td>3</td>\n",
       "      <td>24.279375</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.279375</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291620</td>\n",
       "      <td>0.713954</td>\n",
       "      <td>0.422334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50570</th>\n",
       "      <td>3</td>\n",
       "      <td>26.885317</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.885317</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307303</td>\n",
       "      <td>0.728532</td>\n",
       "      <td>0.421228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82287</th>\n",
       "      <td>2</td>\n",
       "      <td>21.221447</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.221447</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.331384</td>\n",
       "      <td>0.750996</td>\n",
       "      <td>0.419613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>3</td>\n",
       "      <td>25.786879</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.786879</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301614</td>\n",
       "      <td>0.720084</td>\n",
       "      <td>0.418470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>0</td>\n",
       "      <td>34.187998</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.187998</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443864</td>\n",
       "      <td>0.295724</td>\n",
       "      <td>-0.148139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49004</th>\n",
       "      <td>0</td>\n",
       "      <td>31.196287</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.196287</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.446206</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>-0.149327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>0</td>\n",
       "      <td>33.904500</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.904500</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.455569</td>\n",
       "      <td>0.304683</td>\n",
       "      <td>-0.150885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73072</th>\n",
       "      <td>0</td>\n",
       "      <td>29.906484</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.906484</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.282845</td>\n",
       "      <td>-0.154173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64084</th>\n",
       "      <td>0</td>\n",
       "      <td>32.305857</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.305857</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.437237</td>\n",
       "      <td>0.275225</td>\n",
       "      <td>-0.162012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1         V2        V3  V4  V5  V6  V7  promotion_applied  V1_T  \\\n",
       "56603   3  29.585683 -1.684550   2   4   3   1                  1     3   \n",
       "18866   3  24.279375 -1.684550   2   2   4   1                  1     3   \n",
       "50570   3  26.885317 -1.684550   2   4   1   1                  1     3   \n",
       "82287   2  21.221447 -1.684550   2   4   4   1                  1     2   \n",
       "7589    3  25.786879 -1.597972   2   3   3   1                  1     3   \n",
       "...    ..        ...       ...  ..  ..  ..  ..                ...   ...   \n",
       "84212   0  34.187998  1.605406   1   2   2   2                  1     0   \n",
       "49004   0  31.196287  1.691984   1   2   2   2                  1     0   \n",
       "78309   0  33.904500  1.691984   1   3   1   2                  1     0   \n",
       "73072   0  29.906484  1.691984   1   1   2   2                  1     0   \n",
       "64084   0  32.305857  1.691984   1   1   1   2                  1     0   \n",
       "\n",
       "            V2_T      V3_T  V4_T  V5_T  V6_T  V7_T    prob_0    prob_1  \\\n",
       "56603  29.585683 -1.684550     2     4     3     1  0.307462  0.733192   \n",
       "18866  24.279375 -1.684550     2     2     4     1  0.291620  0.713954   \n",
       "50570  26.885317 -1.684550     2     4     1     1  0.307303  0.728532   \n",
       "82287  21.221447 -1.684550     2     4     4     1  0.331384  0.750996   \n",
       "7589   25.786879 -1.597972     2     3     3     1  0.301614  0.720084   \n",
       "...          ...       ...   ...   ...   ...   ...       ...       ...   \n",
       "84212  34.187998  1.605406     1     2     2     2  0.443864  0.295724   \n",
       "49004  31.196287  1.691984     1     2     2     2  0.446206  0.296878   \n",
       "78309  33.904500  1.691984     1     3     1     2  0.455569  0.304683   \n",
       "73072  29.906484  1.691984     1     1     2     2  0.437018  0.282845   \n",
       "64084  32.305857  1.691984     1     1     1     2  0.437237  0.275225   \n",
       "\n",
       "       incremental_prob  \n",
       "56603          0.425730  \n",
       "18866          0.422334  \n",
       "50570          0.421228  \n",
       "82287          0.419613  \n",
       "7589           0.418470  \n",
       "...                 ...  \n",
       "84212         -0.148139  \n",
       "49004         -0.149327  \n",
       "78309         -0.150885  \n",
       "73072         -0.154173  \n",
       "64084         -0.162012  \n",
       "\n",
       "[21134 rows x 18 columns]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sort_values(by=['incremental_prob'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>promotion_applied</th>\n",
       "      <th>V1_T</th>\n",
       "      <th>V2_T</th>\n",
       "      <th>V3_T</th>\n",
       "      <th>V4_T</th>\n",
       "      <th>V5_T</th>\n",
       "      <th>V6_T</th>\n",
       "      <th>V7_T</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>incremental_prob</th>\n",
       "      <th>promotion_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.140341</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366651</td>\n",
       "      <td>0.597853</td>\n",
       "      <td>0.231202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>3</td>\n",
       "      <td>35.295214</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.295214</td>\n",
       "      <td>-0.472461</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.378601</td>\n",
       "      <td>0.647124</td>\n",
       "      <td>0.268523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>2</td>\n",
       "      <td>35.824522</td>\n",
       "      <td>1.085939</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.824522</td>\n",
       "      <td>1.085939</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.442626</td>\n",
       "      <td>0.576285</td>\n",
       "      <td>0.133658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17797</th>\n",
       "      <td>3</td>\n",
       "      <td>22.322402</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.322402</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.352434</td>\n",
       "      <td>1.605406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504949</td>\n",
       "      <td>0.545689</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.675765</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.356628</td>\n",
       "      <td>0.396428</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69178</th>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.199113</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.318143</td>\n",
       "      <td>0.392459</td>\n",
       "      <td>0.074316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36585</th>\n",
       "      <td>2</td>\n",
       "      <td>32.978397</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32.978397</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.386402</td>\n",
       "      <td>0.599068</td>\n",
       "      <td>0.212666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72707</th>\n",
       "      <td>1</td>\n",
       "      <td>30.369647</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.369647</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343215</td>\n",
       "      <td>0.409188</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58509</th>\n",
       "      <td>3</td>\n",
       "      <td>29.885528</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.885528</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.403063</td>\n",
       "      <td>0.562642</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1         V2        V3  V4  V5  V6  V7  promotion_applied  V1_T  \\\n",
       "74988   3  25.140341  0.047006   2   1   3   2                  1     3   \n",
       "26819   3  35.295214 -0.472461   2   4   1   2                  1     3   \n",
       "61906   2  35.824522  1.085939   2   3   3   2                  1     2   \n",
       "17797   3  22.322402  0.826206   1   3   1   2                  1     3   \n",
       "44793   0  30.352434  1.605406   2   2   2   2                  1     0   \n",
       "...    ..        ...       ...  ..  ..  ..  ..                ...   ...   \n",
       "73605   0  26.675765 -1.078506   1   1   2   2                  1     0   \n",
       "69178   1  37.199113 -1.597972   1   1   1   2                  1     1   \n",
       "36585   2  32.978397 -0.212728   2   1   3   2                  1     2   \n",
       "72707   1  30.369647  0.133583   1   3   4   1                  1     1   \n",
       "58509   3  29.885528  0.999361   2   2   2   2                  1     3   \n",
       "\n",
       "            V2_T      V3_T  V4_T  V5_T  V6_T  V7_T    prob_0    prob_1  \\\n",
       "74988  25.140341  0.047006     2     1     3     2  0.366651  0.597853   \n",
       "26819  35.295214 -0.472461     2     4     1     2  0.378601  0.647124   \n",
       "61906  35.824522  1.085939     2     3     3     2  0.442626  0.576285   \n",
       "17797  22.322402  0.826206     1     3     1     2  0.348436  0.346697   \n",
       "44793  30.352434  1.605406     2     2     2     2  0.504949  0.545689   \n",
       "...          ...       ...   ...   ...   ...   ...       ...       ...   \n",
       "73605  26.675765 -1.078506     1     1     2     2  0.356628  0.396428   \n",
       "69178  37.199113 -1.597972     1     1     1     2  0.318143  0.392459   \n",
       "36585  32.978397 -0.212728     2     1     3     2  0.386402  0.599068   \n",
       "72707  30.369647  0.133583     1     3     4     1  0.343215  0.409188   \n",
       "58509  29.885528  0.999361     2     2     2     2  0.403063  0.562642   \n",
       "\n",
       "       incremental_prob  promotion_app  \n",
       "74988          0.231202              1  \n",
       "26819          0.268523              0  \n",
       "61906          0.133658              0  \n",
       "17797         -0.001739              0  \n",
       "44793          0.040741              1  \n",
       "...                 ...            ...  \n",
       "73605          0.039800              1  \n",
       "69178          0.074316              1  \n",
       "36585          0.212666              0  \n",
       "72707          0.065973              0  \n",
       "58509          0.159579              0  \n",
       "\n",
       "[21134 rows x 19 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([X_test[['prob_0', 'prob_1', 'incremental_prob', 'promotion_app']], y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>incremental_prob</th>\n",
       "      <th>promotion_app</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>0.366651</td>\n",
       "      <td>0.597853</td>\n",
       "      <td>0.231202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>0.378601</td>\n",
       "      <td>0.647124</td>\n",
       "      <td>0.268523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>0.442626</td>\n",
       "      <td>0.576285</td>\n",
       "      <td>0.133658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17797</th>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44793</th>\n",
       "      <td>0.504949</td>\n",
       "      <td>0.545689</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>0.356628</td>\n",
       "      <td>0.396428</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69178</th>\n",
       "      <td>0.318143</td>\n",
       "      <td>0.392459</td>\n",
       "      <td>0.074316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36585</th>\n",
       "      <td>0.386402</td>\n",
       "      <td>0.599068</td>\n",
       "      <td>0.212666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72707</th>\n",
       "      <td>0.343215</td>\n",
       "      <td>0.409188</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58509</th>\n",
       "      <td>0.403063</td>\n",
       "      <td>0.562642</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob_0    prob_1  incremental_prob  promotion_app  purchase\n",
       "74988  0.366651  0.597853          0.231202              1         0\n",
       "26819  0.378601  0.647124          0.268523              0         0\n",
       "61906  0.442626  0.576285          0.133658              0         0\n",
       "17797  0.348436  0.346697         -0.001739              0         0\n",
       "44793  0.504949  0.545689          0.040741              1         0\n",
       "...         ...       ...               ...            ...       ...\n",
       "73605  0.356628  0.396428          0.039800              1         0\n",
       "69178  0.318143  0.392459          0.074316              1         0\n",
       "36585  0.386402  0.599068          0.212666              0         0\n",
       "72707  0.343215  0.409188          0.065973              0         0\n",
       "58509  0.403063  0.562642          0.159579              0         0\n",
       "\n",
       "[21134 rows x 5 columns]"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>incremental_prob</th>\n",
       "      <th>promotion_app</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56603</th>\n",
       "      <td>0.307462</td>\n",
       "      <td>0.733192</td>\n",
       "      <td>0.425730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18866</th>\n",
       "      <td>0.291620</td>\n",
       "      <td>0.713954</td>\n",
       "      <td>0.422334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50570</th>\n",
       "      <td>0.307303</td>\n",
       "      <td>0.728532</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82287</th>\n",
       "      <td>0.331384</td>\n",
       "      <td>0.750996</td>\n",
       "      <td>0.419613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>0.301614</td>\n",
       "      <td>0.720084</td>\n",
       "      <td>0.418470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>0.443864</td>\n",
       "      <td>0.295724</td>\n",
       "      <td>-0.148139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49004</th>\n",
       "      <td>0.446206</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>-0.149327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>0.455569</td>\n",
       "      <td>0.304683</td>\n",
       "      <td>-0.150885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73072</th>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.282845</td>\n",
       "      <td>-0.154173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64084</th>\n",
       "      <td>0.437237</td>\n",
       "      <td>0.275225</td>\n",
       "      <td>-0.162012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob_0    prob_1  incremental_prob  promotion_app  purchase\n",
       "56603  0.307462  0.733192          0.425730              0         0\n",
       "18866  0.291620  0.713954          0.422334              0         0\n",
       "50570  0.307303  0.728532          0.421228              0         0\n",
       "82287  0.331384  0.750996          0.419613              1         0\n",
       "7589   0.301614  0.720084          0.418470              1         0\n",
       "...         ...       ...               ...            ...       ...\n",
       "84212  0.443864  0.295724         -0.148139              1         0\n",
       "49004  0.446206  0.296878         -0.149327              0         0\n",
       "78309  0.455569  0.304683         -0.150885              0         0\n",
       "73072  0.437018  0.282845         -0.154173              1         0\n",
       "64084  0.437237  0.275225         -0.162012              1         0\n",
       "\n",
       "[21134 rows x 5 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sort_values(by=['incremental_prob'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['quantile'] = pd.qcut(final['incremental_prob'], q=20, labels=False)\n",
    "final['groupings'] = pd.qcut(final['incremental_prob'], q=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>incremental_prob</th>\n",
       "      <th>promotion_app</th>\n",
       "      <th>purchase</th>\n",
       "      <th>quantile</th>\n",
       "      <th>groupings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56603</th>\n",
       "      <td>0.307462</td>\n",
       "      <td>0.733192</td>\n",
       "      <td>0.425730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>(0.334, 0.426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18866</th>\n",
       "      <td>0.291620</td>\n",
       "      <td>0.713954</td>\n",
       "      <td>0.422334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>(0.334, 0.426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50570</th>\n",
       "      <td>0.307303</td>\n",
       "      <td>0.728532</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>(0.334, 0.426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82287</th>\n",
       "      <td>0.331384</td>\n",
       "      <td>0.750996</td>\n",
       "      <td>0.419613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>(0.334, 0.426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>0.301614</td>\n",
       "      <td>0.720084</td>\n",
       "      <td>0.418470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>(0.334, 0.426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>0.443864</td>\n",
       "      <td>0.295724</td>\n",
       "      <td>-0.148139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.163, -0.0591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49004</th>\n",
       "      <td>0.446206</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>-0.149327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.163, -0.0591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>0.455569</td>\n",
       "      <td>0.304683</td>\n",
       "      <td>-0.150885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.163, -0.0591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73072</th>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.282845</td>\n",
       "      <td>-0.154173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.163, -0.0591]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64084</th>\n",
       "      <td>0.437237</td>\n",
       "      <td>0.275225</td>\n",
       "      <td>-0.162012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.163, -0.0591]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21134 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob_0    prob_1  incremental_prob  promotion_app  purchase  \\\n",
       "56603  0.307462  0.733192          0.425730              0         0   \n",
       "18866  0.291620  0.713954          0.422334              0         0   \n",
       "50570  0.307303  0.728532          0.421228              0         0   \n",
       "82287  0.331384  0.750996          0.419613              1         0   \n",
       "7589   0.301614  0.720084          0.418470              1         0   \n",
       "...         ...       ...               ...            ...       ...   \n",
       "84212  0.443864  0.295724         -0.148139              1         0   \n",
       "49004  0.446206  0.296878         -0.149327              0         0   \n",
       "78309  0.455569  0.304683         -0.150885              0         0   \n",
       "73072  0.437018  0.282845         -0.154173              1         0   \n",
       "64084  0.437237  0.275225         -0.162012              1         0   \n",
       "\n",
       "       quantile          groupings  \n",
       "56603        19     (0.334, 0.426]  \n",
       "18866        19     (0.334, 0.426]  \n",
       "50570        19     (0.334, 0.426]  \n",
       "82287        19     (0.334, 0.426]  \n",
       "7589         19     (0.334, 0.426]  \n",
       "...         ...                ...  \n",
       "84212         0  (-0.163, -0.0591]  \n",
       "49004         0  (-0.163, -0.0591]  \n",
       "78309         0  (-0.163, -0.0591]  \n",
       "73072         0  (-0.163, -0.0591]  \n",
       "64084         0  (-0.163, -0.0591]  \n",
       "\n",
       "[21134 rows x 7 columns]"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sort_values(by=['incremental_prob'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006371849738468854"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.groupby(['promotion_app'])['purchase'].mean()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nir = []\n",
    "# for i in range(19,-1,-1):\n",
    "#     nir.append(final[final['quantile']>=i].groupby(['promotion_app'])['purchase'].mean()[1] - final[final['quantile']>=i].groupby(['promotion_app'])['purchase'].mean()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_irr = dict()\n",
    "for i in range(19,-1,-1):\n",
    "    cum_irr[i] = (final[final['quantile']>=i].groupby(['promotion_app'])['purchase'].mean()[1] - final[final['quantile']>=i].groupby(['promotion_app'])['purchase'].mean()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile = list(cum_irr.keys())\n",
    "cum_irrs = list(cum_irr.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(quantile, cum_irrs)\n",
    "ax.set_xticks(range(len(quantile)))\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19: 0.008378925602033344,\n",
       " 18: 0.014552936373208413,\n",
       " 17: 0.01482293063416281,\n",
       " 16: 0.015454811686253015,\n",
       " 15: 0.015886498482305795,\n",
       " 14: 0.016343163235774748,\n",
       " 13: 0.018071235677700765,\n",
       " 12: 0.0180960237843114,\n",
       " 11: 0.018300838611514103,\n",
       " 10: 0.0162690302868993,\n",
       " 9: 0.016915359376043555,\n",
       " 8: 0.01709137421351986,\n",
       " 7: 0.016541486782187,\n",
       " 6: 0.015640653703024636,\n",
       " 5: 0.016130029446901614,\n",
       " 4: 0.015718334599700352,\n",
       " 3: 0.015152221313006746,\n",
       " 2: 0.013546727968281057,\n",
       " 1: 0.012320588433359772,\n",
       " 0: 0.011803119656012735}"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of purchasers that received the promotion times 10 minus the number of promotions given times 0.15 minus the number of purchasers who were not given the promotion times 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_nir = dict()\n",
    "for i in range(19,-1,-1):\n",
    "    cum_nir[i] = \\\n",
    "    final[(final['quantile']>=i) & (final['promotion_app']==1) & (final['purchase']==1)]['purchase'].count()*10 - \\\n",
    "    final[(final['quantile']>=i) & (final['promotion_app']==1)]['purchase'].count()*0.15 - \\\n",
    "    final[(final['quantile']>=i) & (final['promotion_app']==0) & (final['purchase']==1)]['purchase'].count()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile = list(cum_nir.keys())\n",
    "cum_nirs = list(cum_nir.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(quantile, cum_nirs)\n",
    "ax.set_xticks(range(len(quantile)))\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19: -35.14999999999999,\n",
       " 18: -5.699999999999989,\n",
       " 17: -4.599999999999994,\n",
       " 16: 6.350000000000023,\n",
       " 15: 18.80000000000001,\n",
       " 14: 38.700000000000045,\n",
       " 13: 109.35000000000002,\n",
       " 12: 128.5,\n",
       " 11: 152.0,\n",
       " 10: 67.25,\n",
       " 9: 114.60000000000002,\n",
       " 8: 135.55000000000007,\n",
       " 7: 107.70000000000005,\n",
       " 6: 48.799999999999955,\n",
       " 5: 90.35000000000014,\n",
       " 4: 61.299999999999955,\n",
       " 3: 17.600000000000136,\n",
       " 2: -133.25,\n",
       " 1: -263.64999999999986,\n",
       " 0: -332.8499999999999}"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[(final['quantile']>=19) & (final['promotion_app']==0) & (final['purchase']==1)]['purchase'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on your how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
